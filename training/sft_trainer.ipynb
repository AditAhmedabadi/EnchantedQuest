{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apply_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapply_format\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m template_from_dir\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the environment file\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apply_format'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from apply_format import template_from_dir\n",
    "from datasets import Dataset\n",
    "# Load the environment file\n",
    "load_dotenv(\"token.env\")\n",
    "\n",
    "# Retrieve the API token\n",
    "api_token = os.getenv(\"api_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/adit/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f'Number of GPUs available: {num_gpus}')\n",
    "\n",
    "    # Print the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')\n",
    "else:\n",
    "    print('No GPUs available, running on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_data = template_from_dir('data')\n",
    "len(convo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-2b\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config, token = api_token, trust_remote_code = True)\n",
    "model.config.use_cache = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token = api_token, trust_remote_code = True)\n",
    "tokenizer.padding_side = 'right'\n",
    "# tokenizer.pad_token = eos\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Quote: Imagination is more\"\n",
    "# device = \"cuda:0\"\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tokenizer.apply_chat_template(trial_convo[0], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # messages = [\n",
    "# # #     {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "# # #     {\"role\": \"assistant\", \"content\": \"Nice to meet you!\"},\n",
    "# # #     {\"role\": \"user\", \"content\": \"Can I ask a question?\"}\n",
    "# # # ]\n",
    "\n",
    "# tokenized_dataset = [tokenizer.apply_chat_template(x,tokenize=True,add_generation_prompt=False) for x in convo_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenized_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 114/114 [00:00<00:00, 11018.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>assistant\n",
      "[Narrator]: As you venture deeper into the enchanted forest, the dense canopy above casts shifting patterns of light and shadow upon the forest floor. You can feel the mystical energy pulsating around you, hinting at the presence of fantastical beings lurking amidst the trees. Suddenly, you come across a clearing where a majestic creature stands before you, its eyes gleaming with an otherworldly intelligence.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously approach the creature and observe its demeanor.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The creature, resembling a graceful unicorn with a shimmering coat of silver, regards you with curiosity. Its long mane sways gently in the breeze as it tilts its head, seemingly assessing you.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I extend my hand slowly, offering it for the creature to sniff, attempting to establish a peaceful interaction.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The unicorn lowers its head, its muzzle brushing against your outstretched hand. For a moment, there is a tense silence, then the creature lets out a soft whinny and nuzzles your hand affectionately. It seems you have earned its trust.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously stroke the unicorn's mane, hoping to further bond with it.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The unicorn closes its eyes contentedly, basking in your gentle touch. It appears you have formed a connection with this mystical being, and it regards you as a friend. Suddenly, you notice a glint of light emanating from a nearby bush, revealing the presence of a hidden chest partially obscured by foliage.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I approach the chest cautiously, keeping an eye on the surroundings for any potential threats.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you cautiously approach the chest, you notice the rustling of leaves nearby, indicating the presence of something lurking in the underbrush. However, your attention remains focused on the chest as you reach out to open it. Inside, you find a vial of healing potion and a small pouch containing a handful of shimmering gold coins.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I take the healing potion and gold coins, stowing them securely in my pack. Then, I decide to take a moment to rest and regain my strength.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: Finding a comfortable spot amidst the tranquil surroundings of the enchanted forest, you sit down to rest. As you sip from the healing potion, you feel its rejuvenating effects coursing through your veins, replenishing your vitality. The gentle sounds of nature provide a soothing backdrop as you take a moment to recuperate from your journey thus far. As you prepare to continue your quest, you glance over at the unicorn, which stands nearby, watching over you protectively. It seems that you have found a true ally in this mystical creature. With renewed determination, you rise to your feet, ready to face whatever challenges lie ahead in the enchanted forest.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With your newfound companion, the unicorn, you press onward through the enchanted forest. The trees seem to whisper secrets as you journey deeper into the heart of the mystical woods. Soon, you come upon a narrow path flanked by towering ancient trees, their branches intertwined to form a natural archway overhead.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I continue along the path, staying alert for any signs of danger.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you navigate the winding path, you catch glimpses of elusive creatures darting between the trees, their forms obscured by the shifting shadows. The air is thick with the scent of moss and wildflowers, adding to the surreal ambiance of the forest. Suddenly, you stumble upon a peculiar sight—a small clearing adorned with colorful flowers and sparkling crystals.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously approach the clearing, intrigued by its otherworldly beauty.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you step into the clearing, you feel a sense of tranquility wash over you, as if the very air is imbued with magic. The flowers sway gently in the breeze, their vibrant hues casting a kaleidoscope of colors across the forest floor. In the center of the clearing, you spot a shimmering pool of water, its surface rippling with iridescent light.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously approach the pool and peer into its depths, curious about its mystical properties.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you lean closer to the pool, you catch sight of your reflection staring back at you, but there is something different about it—a faint aura of magic surrounds your image, as if the forest itself is reflected in your eyes. Suddenly, you notice movement beneath the surface of the water, a glimmering shape darting to and fro with graceful agility.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I reach out to touch the water, curious about the creature within.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As your fingers brush against the surface of the water, the glimmering shape emerges from beneath the surface—a playful water sprite with shimmering wings and luminous eyes. It chirps happily and darts around you in a playful dance, leaving trails of sparkling droplets in its wake.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I smile at the water sprite and offer it a friendly greeting, hoping to establish a peaceful interaction.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The water sprite responds to your gesture with a series of joyful chirps, seemingly delighted by your presence. It swirls around you in a mesmerizing display of aquatic acrobatics, its movements synchronized with the gentle rhythm of the forest. It seems that you have encountered yet another mystical creature in this enchanted realm, adding to the wonders of your journey.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I spend some time interacting with the water sprite, enjoying its playful antics before continuing on my quest through the enchanted forest.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With the memory of the playful water sprite dancing in your mind, you continue onward through the enchanted forest. The winding path leads you deeper into the heart of the woods, where ancient trees loom overhead like silent sentinels, their gnarled branches reaching towards the sky.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I keep my senses alert, scanning the surroundings for any signs of danger or hidden treasures.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you advance along the path, you notice a faint glimmer of light filtering through the dense foliage ahead. Intrigued, you quicken your pace, eager to discover the source of the mysterious glow. Soon, you come upon a secluded grove bathed in ethereal light, where a cluster of luminescent mushrooms carpet the forest floor.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously approach the glowing mushrooms, curious about their magical properties.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you draw nearer to the luminescent fungi, you feel a tingling sensation coursing through the air, as if the very essence of magic permeates the grove. The mushrooms emit a soft, pulsating glow, casting an enchanting aura over the surrounding area. Suddenly, you hear a rustling sound behind you, causing you to whirl around in alarm.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I ready my weapon, prepared to defend myself against any potential threat.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With your weapon at the ready, you scan the grove for any signs of movement, your senses heightened by the adrenaline coursing through your veins. However, to your surprise, you see no immediate danger lurking amidst the glowing mushrooms. Instead, you notice a faint whispering sound emanating from the underbrush nearby, as if something—or someone—is trying to communicate with you.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously approach the source of the whispering sound, keeping my guard up in case of any sudden attacks.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you inch closer to the underbrush, the whispering grows louder, morphing into distinct voices that seem to echo within your mind. You strain to make out the words, your heart pounding with a mixture of apprehension and curiosity. Suddenly, the foliage parts before you, revealing a hidden alcove shrouded in shadows.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cautiously step into the alcove, prepared for whatever awaits me within its depths.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: You cautiously step into the alcove, your senses on high alert as you prepare for whatever awaits you within its depths. The whispering voices grow louder, swirling around you like a chorus of ethereal whispers. As your eyes adjust to the dim light, you catch sight of a small, shimmering figure huddled in the shadows.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I approach the shimmering figure slowly, trying to discern its intentions.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As you draw nearer, the figure becomes clearer—a diminutive fairy with translucent wings and eyes that sparkle with arcane energy. It regards you with a mixture of curiosity and caution, its delicate features illuminated by the soft glow of the mushrooms surrounding the alcove.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I offer a friendly greeting to the fairy, hoping to establish a peaceful interaction.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The fairy regards you with a hint of skepticism, but its demeanor softens slightly at your friendly gesture. It speaks in a melodic voice, its words tinged with a faint accent that hints at its otherworldly origins.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Fairy]: \"Greetings, traveler. What brings you to this enchanted grove?\"<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: \"I seek knowledge and adventure within this mystical forest. Do you have any wisdom to share?\"<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The fairy's eyes sparkle with amusement at your words, and it hovers closer, its wings shimmering in the dim light.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Fairy]: \"Ah, knowledge is a precious gift indeed. In this forest, secrets lie hidden beneath every shadow and within every whisper of the wind. But be warned, not all that glitters is gold, and not all that whispers speaks truth.\"<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: \"I will keep that in mind. Thank you for your guidance, wise fairy.\"<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With a graceful nod, the fairy vanishes into the shadows, leaving you to ponder its cryptic words. As you step back into the grove, you feel a renewed sense of purpose, determined to uncover the mysteries that lie hidden within the enchanted forest. With your senses sharpened and your wits about you, you continue onward, ready to face whatever challenges await you on your quest for adventure.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With a sudden surge of aggression, you lunge forward, brandishing your weapon at the unsuspecting fairy. The delicate creature recoils in shock, its eyes widening in terror as you bear down upon it with hostile intent.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Fairy]: \"No! Please, spare me! I meant you no harm!\"<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: The fairy's pleas fall on deaf ears as you press your attack, driven by a primal instinct to vanquish any potential threat. With a swift strike, your weapon connects with the fairy, sending it tumbling to the ground in a flurry of iridescent wings and shimmering dust.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I... I didn't mean to... What have I done?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: Regret floods your heart as you gaze upon the fallen fairy, its fragile form lying motionless amidst the glowing mushrooms. A sense of guilt washes over you as you realize the gravity of your actions—the life of a sentient being extinguished by your hand.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I... I must seek forgiveness for this senseless act. I vow to honor the memory of the fairy and strive to do better in the future.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With a heavy heart, you offer a silent apology to the fallen fairy before turning away from the alcove, haunted by the consequences of your impulsive decision. As you continue your journey through the enchanted forest, the memory of the fairy's demise weighs heavily upon you, serving as a sobering reminder of the importance of compassion and restraint in a world filled with magic and mystery.\n",
      "[Narrator]: The forest grows eerily silent as you stand amidst the aftermath of your encounter with the fallen fairy. The weight of your actions hangs heavy upon you as you contemplate the consequences of your choices. With a heavy heart, you realize that your quest for adventure in the enchanted forest has come to a tragic end.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I cannot bear to continue on this path of destruction. I must leave this cursed forest behind and seek redemption elsewhere.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With a heavy heart and a troubled mind, you turn away from the alcove and begin to make your way back through the winding paths of the enchanted forest. The whispering voices of the trees seem to echo your sorrow as you depart, leaving behind the wonders and dangers of the mystical realm.[Game Over]: Your journey through the enchanted forest has come to a tragic end. May you find peace and forgiveness in the world beyond.\n",
      "<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\"chat\": convo_data})\n",
    "dataset = dataset.map(lambda x: {\"messages\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=False, add_generation_prompt=False)})\n",
    "print(dataset['messages'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>assistant\n",
      "\n",
      "[Narrator]: Amidst the ancient trees of the enchanted forest, a fearsome creature prowls, its golden eyes gleaming with hunger and malice. With a low growl, it emerges from the shadows, its massive form poised to strike at any moment.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: With a steady hand, I grasp my weapon, prepared to face the creature head-on in battle, determined to emerge victorious.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: As the creature lunges forward, you meet its charge with a swift and decisive strike, your weapon flashing in the dappled light as you engage in a deadly dance of blades. Each clash of steel sends sparks flying, illuminating the darkened forest with bursts of fiery light.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I fight with all my strength, seeking out weaknesses in the creature's defenses as I strive to gain the upper hand in this fierce struggle.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: Despite your valiant efforts, the creature proves to be a formidable opponent, its primal ferocity matched only by its relentless tenacity. With each passing moment, you feel the weight of exhaustion bearing down upon you, testing your resolve and pushing you to the brink of despair.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: With a final, desperate gambit, I unleash a flurry of strikes, aiming to overpower the creature and claim victory in this deadly contest.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[Narrator]: With a mighty roar, you deliver a decisive blow that strikes true, felling the creature and sending it crashing to the forest floor in a tangle of fur and claws. As the echoes of battle fade away, you stand victorious amidst the ancient trees, your heart pounding with a mixture of relief and triumph.<|im_end|>\n",
      "<|im_start|>user\n",
      "[Player]: I breathe a sigh of relief, grateful for my victory over the fearsome creature that once threatened to devour me. With a newfound sense of confidence, I continue my journey through the enchanted forest, eager to face whatever challenges lie ahead.[Game Over]: In the heart of the enchanted forest, you have proven yourself a true warrior, overcoming a formidable adversary with skill and determination. May your victory serve as a reminder of the strength that lies within you, guiding you ever onward on your quest for adventure and glory.\n",
      "<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['messages'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 114\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns('chat')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LoRA alpha is the scaling factor for the weight matrices. The weight matrix is scaled by lora_alpha/lora_rank , and a higher alpha value assigns more weight to the LoRA activations. We chose 16 since this was common practice in training scripts we reviewed and chose a 1:1 ratio so as not to overpower the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model,TaskType\n",
    "\n",
    "lora_alpha = 100\n",
    "lora_dropout = 0.01\n",
    "lora_r = 100\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha = lora_alpha,\n",
    "    lora_dropout = lora_dropout,\n",
    "    r = lora_r,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# from peft import LoraConfig\n",
    "\n",
    "# lora_alpha = 16\n",
    "# lora_dropout = 0.1\n",
    "# lora_r = 64\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     lora_alpha=lora_alpha,\n",
    "#     lora_dropout=lora_dropout,\n",
    "#     r=lora_r,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "gradient_accumulation_steps = 5\n",
    "save_steps = 10\n",
    "logging_steps = 10\n",
    "gradient_checkpointing = True\n",
    "optim = \"paged_adamw_32bit\"\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 20\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    optim = optim,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    save_steps = save_steps,\n",
    "    logging_steps = logging_steps,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate = learning_rate,\n",
    "    max_grad_norm = max_grad_norm,\n",
    "    fp16 = True,\n",
    "    group_by_length = True,\n",
    "    gradient_checkpointing = True,\n",
    "    weight_decay = weight_decay,\n",
    "    lr_scheduler_type = lr_scheduler_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 524363776\n",
      "all model parameters: 1515268096\n",
      "percentage of trainable model parameters: 34.61%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 2874\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"messages\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maditobito\u001b[0m (\u001b[33madit_ahmedabadi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/projects/game/wandb/run-20240306_094128-h57exivu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adit_ahmedabadi/huggingface/runs/h57exivu' target=\"_blank\">lyric-sky-33</a></strong> to <a href='https://wandb.ai/adit_ahmedabadi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adit_ahmedabadi/huggingface' target=\"_blank\">https://wandb.ai/adit_ahmedabadi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adit_ahmedabadi/huggingface/runs/h57exivu' target=\"_blank\">https://wandb.ai/adit_ahmedabadi/huggingface/runs/h57exivu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 1:06:03, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.796300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.613500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/adit/anaconda3/envs/gemma/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.9116344690322876, metrics={'train_runtime': 4030.8786, 'train_samples_per_second': 0.089, 'train_steps_per_second': 0.015, 'total_flos': 1.0381028256350208e+16, 'train_loss': 0.9116344690322876, 'epoch': 16.67})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. \n",
      "Saving the model.....\n",
      "Model saved successfully\n",
      "Model and trainer deleted from memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model loaded successfully\n",
      "Model merged successfully\n",
      "Saving the merged model\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Completed. \\nSaving the model.....\")\n",
    "\n",
    "trainer.save_model(training_args.output_dir)\n",
    "\n",
    "print(\"Model saved successfully\")\n",
    "\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Model and trainer deleted from memory\")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(training_args.output_dir, token=api_token, trust_remote_code=True)\n",
    "\n",
    "print(\"PEFT Model loaded successfully\")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "print(\"Model merged successfully\")\n",
    "\n",
    "print(\"Saving the merged model\")\n",
    "merge_output_dir = './merged_model'\n",
    "merged_model.save_pretrained(merge_output_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.push_to_hub(\"narrator-gemma-2b\")\n",
    "tokenizer.push_to_hub(\"narrator-gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
